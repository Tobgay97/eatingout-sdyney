{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb034e01-b4fc-4298-bbf1-34aa165ce164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (10500, 17)\n",
      "\n",
      "Engineered dataframe (data) preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>lat</th>\n",
       "      <th>link</th>\n",
       "      <th>lng</th>\n",
       "      <th>phone</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>rating_text</th>\n",
       "      <th>subzone</th>\n",
       "      <th>...</th>\n",
       "      <th>groupon</th>\n",
       "      <th>color</th>\n",
       "      <th>cost_2</th>\n",
       "      <th>cuisine_color</th>\n",
       "      <th>cuisine_count</th>\n",
       "      <th>has_rating</th>\n",
       "      <th>votes_log1p</th>\n",
       "      <th>lat_bucket</th>\n",
       "      <th>lng_bucket</th>\n",
       "      <th>cost_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371A Pitt Street, CBD, Sydney</td>\n",
       "      <td>50.0</td>\n",
       "      <td>['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean']</td>\n",
       "      <td>-33.876059</td>\n",
       "      <td>https://www.zomato.com/sydney/sydney-madang-cbd</td>\n",
       "      <td>151.207605</td>\n",
       "      <td>02 8318 0406</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>CBD</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#e15307</td>\n",
       "      <td>5.243902</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.179308</td>\n",
       "      <td>-33.876</td>\n",
       "      <td>151.208</td>\n",
       "      <td>(40.0, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shop 7A, 2 Huntley Street, Alexandria, Sydney</td>\n",
       "      <td>80.0</td>\n",
       "      <td>['Cafe', 'Coffee and Tea', 'Salad', 'Poké']</td>\n",
       "      <td>-33.910999</td>\n",
       "      <td>https://www.zomato.com/sydney/the-grounds-of-a...</td>\n",
       "      <td>151.193793</td>\n",
       "      <td>02 9699 2225</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Grounds of Alexandria, Alexandria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#9c3203</td>\n",
       "      <td>7.560976</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8.082402</td>\n",
       "      <td>-33.911</td>\n",
       "      <td>151.194</td>\n",
       "      <td>(70.0, 500.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level G, The Darling at the Star, 80 Pyrmont ...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Japanese']</td>\n",
       "      <td>-33.867971</td>\n",
       "      <td>https://www.zomato.com/sydney/sokyo-pyrmont</td>\n",
       "      <td>151.195210</td>\n",
       "      <td>1800 700 700</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Star, Pyrmont</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>10.650407</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.113142</td>\n",
       "      <td>-33.868</td>\n",
       "      <td>151.195</td>\n",
       "      <td>(70.0, 500.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydney Opera House, Bennelong Point, Circular...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>['Modern Australian']</td>\n",
       "      <td>-33.856784</td>\n",
       "      <td>https://www.zomato.com/sydney/bennelong-restau...</td>\n",
       "      <td>151.215297</td>\n",
       "      <td>02 9240 8000</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Circular Quay</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>22.235772</td>\n",
       "      <td>#4186f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.631212</td>\n",
       "      <td>-33.857</td>\n",
       "      <td>151.215</td>\n",
       "      <td>(70.0, 500.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 Campbell Street, Chinatown, Sydney</td>\n",
       "      <td>55.0</td>\n",
       "      <td>['Thai', 'Salad']</td>\n",
       "      <td>-33.879035</td>\n",
       "      <td>https://www.zomato.com/sydney/chat-thai-chinatown</td>\n",
       "      <td>151.206409</td>\n",
       "      <td>02 8317 4811</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>#a83703</td>\n",
       "      <td>5.630081</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.673688</td>\n",
       "      <td>-33.879</td>\n",
       "      <td>151.206</td>\n",
       "      <td>(50.0, 70.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address   cost  \\\n",
       "0                      371A Pitt Street, CBD, Sydney   50.0   \n",
       "1      Shop 7A, 2 Huntley Street, Alexandria, Sydney   80.0   \n",
       "2   Level G, The Darling at the Star, 80 Pyrmont ...  120.0   \n",
       "3   Sydney Opera House, Bennelong Point, Circular...  270.0   \n",
       "4              20 Campbell Street, Chinatown, Sydney   55.0   \n",
       "\n",
       "                                       cuisine        lat  \\\n",
       "0   ['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean'] -33.876059   \n",
       "1  ['Cafe', 'Coffee and Tea', 'Salad', 'Poké'] -33.910999   \n",
       "2                                 ['Japanese'] -33.867971   \n",
       "3                        ['Modern Australian'] -33.856784   \n",
       "4                            ['Thai', 'Salad'] -33.879035   \n",
       "\n",
       "                                                link         lng  \\\n",
       "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
       "1  https://www.zomato.com/sydney/the-grounds-of-a...  151.193793   \n",
       "2        https://www.zomato.com/sydney/sokyo-pyrmont  151.195210   \n",
       "3  https://www.zomato.com/sydney/bennelong-restau...  151.215297   \n",
       "4  https://www.zomato.com/sydney/chat-thai-chinatown  151.206409   \n",
       "\n",
       "          phone  rating_number rating_text  \\\n",
       "0  02 8318 0406            4.0   Very Good   \n",
       "1  02 9699 2225            4.6   Excellent   \n",
       "2  1800 700 700            4.9   Excellent   \n",
       "3  02 9240 8000            4.9   Excellent   \n",
       "4  02 8317 4811            4.5   Excellent   \n",
       "\n",
       "                                 subzone  ... groupon    color     cost_2  \\\n",
       "0                                    CBD  ...       0  #e15307   5.243902   \n",
       "1  The Grounds of Alexandria, Alexandria  ...       0  #9c3203   7.560976   \n",
       "2                      The Star, Pyrmont  ...       0  #7f2704  10.650407   \n",
       "3                          Circular Quay  ...       0  #7f2704  22.235772   \n",
       "4                              Chinatown  ...       0  #a83703   5.630081   \n",
       "\n",
       "   cuisine_color cuisine_count  has_rating votes_log1p  lat_bucket  \\\n",
       "0        #6f706b             4           1    7.179308     -33.876   \n",
       "1        #6f706b             4           1    8.082402     -33.911   \n",
       "2        #6f706b             1           1    7.113142     -33.868   \n",
       "3        #4186f4             1           1    5.631212     -33.857   \n",
       "4        #6f706b             2           1    7.673688     -33.879   \n",
       "\n",
       "   lng_bucket       cost_bin  \n",
       "0     151.208   (40.0, 50.0]  \n",
       "1     151.194  (70.0, 500.0]  \n",
       "2     151.195  (70.0, 500.0]  \n",
       "3     151.215  (70.0, 500.0]  \n",
       "4     151.206   (50.0, 70.0]  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model matrix (X) shape: (10500, 659)\n",
      "Sample columns: ['cost', 'cuisine', 'lat', 'lng', 'rating_number', 'votes', 'groupon', 'color', 'cost_2', 'cuisine_color', 'cuisine_count', 'has_rating', 'votes_log1p', 'lat_bucket', 'lng_bucket', 'subzone_Abbotsford', 'subzone_ActivateMarketplace UTS, CBD', 'subzone_Alexandria', 'subzone_Amora Hotel Jamison Sydney, CBD', 'subzone_Annandale']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>votes</th>\n",
       "      <th>groupon</th>\n",
       "      <th>color</th>\n",
       "      <th>cost_2</th>\n",
       "      <th>cuisine_color</th>\n",
       "      <th>...</th>\n",
       "      <th>type_['Wine Bar', 'Casual Dining']</th>\n",
       "      <th>type_['Wine Bar']</th>\n",
       "      <th>rating_text_Excellent</th>\n",
       "      <th>rating_text_Good</th>\n",
       "      <th>rating_text_Poor</th>\n",
       "      <th>rating_text_Very Good</th>\n",
       "      <th>cost_bin_(30.0, 40.0]</th>\n",
       "      <th>cost_bin_(40.0, 50.0]</th>\n",
       "      <th>cost_bin_(50.0, 70.0]</th>\n",
       "      <th>cost_bin_(70.0, 500.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean']</td>\n",
       "      <td>-33.876059</td>\n",
       "      <td>151.207605</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#e15307</td>\n",
       "      <td>5.243902</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>['Cafe', 'Coffee and Tea', 'Salad', 'Poké']</td>\n",
       "      <td>-33.910999</td>\n",
       "      <td>151.193793</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#9c3203</td>\n",
       "      <td>7.560976</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.0</td>\n",
       "      <td>['Japanese']</td>\n",
       "      <td>-33.867971</td>\n",
       "      <td>151.195210</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>10.650407</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270.0</td>\n",
       "      <td>['Modern Australian']</td>\n",
       "      <td>-33.856784</td>\n",
       "      <td>151.215297</td>\n",
       "      <td>4.9</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>22.235772</td>\n",
       "      <td>#4186f4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>['Thai', 'Salad']</td>\n",
       "      <td>-33.879035</td>\n",
       "      <td>151.206409</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>#a83703</td>\n",
       "      <td>5.630081</td>\n",
       "      <td>#6f706b</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 659 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cost                                      cuisine        lat         lng  \\\n",
       "0   50.0   ['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean'] -33.876059  151.207605   \n",
       "1   80.0  ['Cafe', 'Coffee and Tea', 'Salad', 'Poké'] -33.910999  151.193793   \n",
       "2  120.0                                 ['Japanese'] -33.867971  151.195210   \n",
       "3  270.0                        ['Modern Australian'] -33.856784  151.215297   \n",
       "4   55.0                            ['Thai', 'Salad'] -33.879035  151.206409   \n",
       "\n",
       "   rating_number   votes  groupon    color     cost_2 cuisine_color  ...  \\\n",
       "0            4.0  1311.0        0  #e15307   5.243902       #6f706b  ...   \n",
       "1            4.6  3236.0        0  #9c3203   7.560976       #6f706b  ...   \n",
       "2            4.9  1227.0        0  #7f2704  10.650407       #6f706b  ...   \n",
       "3            4.9   278.0        0  #7f2704  22.235772       #4186f4  ...   \n",
       "4            4.5  2150.0        0  #a83703   5.630081       #6f706b  ...   \n",
       "\n",
       "   type_['Wine Bar', 'Casual Dining']  type_['Wine Bar']  \\\n",
       "0                               False              False   \n",
       "1                               False              False   \n",
       "2                               False              False   \n",
       "3                               False              False   \n",
       "4                               False              False   \n",
       "\n",
       "   rating_text_Excellent  rating_text_Good  rating_text_Poor  \\\n",
       "0                  False             False             False   \n",
       "1                   True             False             False   \n",
       "2                   True             False             False   \n",
       "3                   True             False             False   \n",
       "4                   True             False             False   \n",
       "\n",
       "   rating_text_Very Good  cost_bin_(30.0, 40.0]  cost_bin_(40.0, 50.0]  \\\n",
       "0                   True                  False                   True   \n",
       "1                  False                  False                  False   \n",
       "2                  False                  False                  False   \n",
       "3                  False                  False                  False   \n",
       "4                  False                  False                  False   \n",
       "\n",
       "   cost_bin_(50.0, 70.0]  cost_bin_(70.0, 500.0]  \n",
       "0                  False                   False  \n",
       "1                  False                    True  \n",
       "2                  False                    True  \n",
       "3                  False                    True  \n",
       "4                   True                   False  \n",
       "\n",
       "[5 rows x 659 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Part B: Predictive Modelling\n",
    "\n",
    "# 1 feature engineering \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading data\n",
    "CSV_PATH = r\"C:\\Users\\tobga\\OneDrive\\Desktop\\Data Science\\Sem 3\\Data sci technology and system\\Assignment 1\\zomato_df_final_data.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "\n",
    "# Tidy up column names\n",
    "data = df.copy()\n",
    "data.columns = [c.strip().lower().replace(\" \", \"_\") for c in data.columns]\n",
    "\n",
    "# Fixing basic tpye\n",
    "if \"groupon\" in data.columns:\n",
    "    data[\"groupon\"] = (\n",
    "        data[\"groupon\"].astype(str).str.lower().map({\"true\":1,\"false\":0,\"1\":1,\"0\":0})\n",
    "        .fillna(0).astype(int)\n",
    "    )\n",
    "\n",
    "# Handling missing values\n",
    "num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# numeric -> median\n",
    "for c in num_cols:\n",
    "    if data[c].isna().any():\n",
    "        med = data[c].median()\n",
    "        if pd.notna(med):\n",
    "            data[c] = data[c].fillna(med)\n",
    "\n",
    "# categorical -> most frequent (mode) with safe fallback\n",
    "for c in cat_cols:\n",
    "    if data[c].isna().any():\n",
    "        m = data[c].dropna().mode()\n",
    "        data[c] = data[c].fillna(m.iloc[0] if not m.empty else \"Unknown\")\n",
    "\n",
    "# Exploring simple useful features\n",
    "def split_cuisines(val):\n",
    "    if pd.isna(val): return []\n",
    "    s = str(val)\n",
    "    s = re.sub(r'^\\[|\\]$', '', s)                 # remove [ ... ]\n",
    "    s = s.replace('\"','').replace(\"'\",\"\")         # drop quotes\n",
    "    parts = [p.strip() for p in s.replace(\"/\", \",\").split(\",\") if p.strip()]\n",
    "    return parts\n",
    "\n",
    "# (a) number of cuisines listed\n",
    "if \"cuisine\" in data.columns:\n",
    "    data[\"cuisine_count\"] = data[\"cuisine\"].apply(lambda x: len(split_cuisines(x)))\n",
    "else:\n",
    "    data[\"cuisine_count\"] = 0\n",
    "\n",
    "# (b) has any rating info\n",
    "data[\"has_rating\"] = (\n",
    "    data.get(\"rating_number\", pd.Series([np.nan]*len(data))).notna() |\n",
    "    data.get(\"rating_text\",   pd.Series([np.nan]*len(data))).notna()\n",
    ").astype(int)\n",
    "\n",
    "# (c) log votes to reduce skew \n",
    "if \"votes\" in data.columns:\n",
    "    data[\"votes_log1p\"] = np.log1p(data[\"votes\"].clip(lower=0))\n",
    "\n",
    "# (d) rough location buckets \n",
    "if {\"lat\",\"lng\"}.issubset(data.columns):\n",
    "    data[\"lat_bucket\"] = data[\"lat\"].round(3)\n",
    "    data[\"lng_bucket\"] = data[\"lng\"].round(3)\n",
    "\n",
    "# (e) cost bins for non-linearity\n",
    "if \"cost\" in data.columns:\n",
    "    try:\n",
    "        data[\"cost_bin\"] = pd.qcut(data[\"cost\"], q=5, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        data[\"cost_bin\"] = pd.cut(data[\"cost\"], bins=5)\n",
    "\n",
    "# One-hot encode key categoricals\n",
    "drop_id_cols = [c for c in [\"address\",\"title\",\"link\",\"phone\"] if c in data.columns]\n",
    "X = data.drop(columns=drop_id_cols)\n",
    "\n",
    "onehot_cols = [c for c in [\"subzone\",\"type\",\"rating_text\",\"cost_bin\"] if c in X.columns]\n",
    "X = pd.get_dummies(X, columns=onehot_cols, drop_first=True)\n",
    "\n",
    "# displaying result\n",
    "print(\"\\nEngineered dataframe (data) preview:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nModel matrix (X) shape:\", X.shape)\n",
    "print(\"Sample columns:\", list(X.columns)[:20])\n",
    "display(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f92aa2-b783-4992-96fe-fd4a8b9e6029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (LinearRegression): 45773079018578304.0000\n",
      "MSE (Gradient Descent): 0.1457\n"
     ]
    }
   ],
   "source": [
    "# === Part B\n",
    "# 2 Regression Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Minimal features keeping it simple and numerical\n",
    "data = df.copy()\n",
    "data.columns = [c.strip().lower().replace(\" \", \"_\") for c in data.columns]\n",
    "\n",
    "# Simple cuisine_count\n",
    "def split_cuisines(v):\n",
    "    if pd.isna(v): return []\n",
    "    return [p.strip().strip(\"'\").strip('\"') for p in str(v).replace(\"/\", \",\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\") if p.strip()]\n",
    "\n",
    "data[\"cuisine_count\"] = data.get(\"cuisine\", pd.Series([None]*len(data))).apply(lambda x: len(split_cuisines(x)))\n",
    "data[\"votes\"] = pd.to_numeric(data.get(\"votes\", 0), errors=\"coerce\").fillna(0)\n",
    "data[\"cost\"]  = pd.to_numeric(data.get(\"cost\", 0),  errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Target\n",
    "y = pd.to_numeric(data[\"rating_number\"], errors=\"coerce\")\n",
    "mask = y.notna()\n",
    "data, y = data.loc[mask], y.loc[mask]\n",
    "\n",
    "# One-hot a couple of light categoricals \n",
    "X = data[[\"cost\",\"votes\",\"cuisine_count\",\"type\",\"subzone\"]].copy()\n",
    "X = pd.get_dummies(X, columns=[c for c in [\"type\",\"subzone\"] if c in X.columns], drop_first=True)\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model A: Scikit-Learn Linear Regression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "# Model B: Linear Regression via Gradient Descent (tiny)\n",
    "def standardize_train(A):\n",
    "    mu = A.mean(axis=0); sd = A.std(axis=0, ddof=0); sd[sd==0]=1.0\n",
    "    return (A-mu)/sd, mu, sd\n",
    "\n",
    "def standardize_apply(A, mu, sd):\n",
    "    sd = sd.copy(); sd[sd==0]=1.0\n",
    "    return (A-mu)/sd\n",
    "\n",
    "Xtr_std, mu, sd = standardize_train(X_train.astype(np.float64))\n",
    "Xte_std = standardize_apply(X_test.astype(np.float64), mu, sd)\n",
    "\n",
    "# adding intercept\n",
    "Xtr_b = np.c_[np.ones((Xtr_std.shape[0],1)), Xtr_std]\n",
    "Xte_b = np.c_[np.ones((Xte_std.shape[0],1)), Xte_std]\n",
    "\n",
    "def fit_gd(Xb, y, alpha=0.05, n_iter=2000):\n",
    "    m, n = Xb.shape; theta = np.zeros(n)\n",
    "    for _ in range(n_iter):\n",
    "        theta -= (alpha * 2/m) * (Xb.T @ (Xb @ theta - y))\n",
    "    return theta\n",
    "\n",
    "theta = fit_gd(Xtr_b, y_train.astype(float), alpha=0.05, n_iter=3000)\n",
    "y_pred_gd = Xte_b @ theta\n",
    "mse_gd = mean_squared_error(y_test, y_pred_gd)\n",
    "\n",
    "print(f\"MSE (LinearRegression): {mse_lr:.4f}\")\n",
    "print(f\"MSE (Gradient Descent): {mse_gd:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf68b60-ed6c-4cd5-8447-b5ffa64f0812",
   "metadata": {},
   "source": [
    "**note** I trained two regression models to predict restaurant ratings (rating_number). Both were evaluated with MSE on a held-out 20% test set. The Scikit-Learn Linear Regression gave an MSE of ~0.14, while gradient descent implementation gave an MSE of ~0.15. The results are very similar, confirming gradient descent implementation is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030449bd-a264-4438-a9c2-46b8137977c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobga\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tobga\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg ===\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      " [[887  55]\n",
      " [175 320]]\n",
      "Precision: 0.853 | Recall: 0.646 | F1: 0.736\n",
      "\n",
      "=== RandForest ===\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      " [[842 100]\n",
      " [124 371]]\n",
      "Precision: 0.788 | Recall: 0.749 | F1: 0.768\n",
      "\n",
      "=== GradBoost ===\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      " [[845  97]\n",
      " [ 89 406]]\n",
      "Precision: 0.807 | Recall: 0.820 | F1: 0.814\n",
      "\n",
      "=== LinearSVM ===\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      " [[891  51]\n",
      " [210 285]]\n",
      "Precision: 0.848 | Recall: 0.576 | F1: 0.686\n",
      "\n",
      "=== MLP ===\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      " [[834 108]\n",
      " [ 93 402]]\n",
      "Precision: 0.788 | Recall: 0.812 | F1: 0.800\n",
      "\n",
      "=== Model comparison (sorted by F1) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradBoost</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandForest</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision  Recall     F1\n",
       "GradBoost       0.807   0.820  0.814\n",
       "MLP             0.788   0.812  0.800\n",
       "RandForest      0.788   0.749  0.768\n",
       "LogReg          0.853   0.646  0.736\n",
       "LinearSVM       0.848   0.576  0.686"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Part B\n",
    "# 3 Classification Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "data = df.copy()\n",
    "data.columns = [c.strip().lower().replace(\" \", \"_\") for c in data.columns]\n",
    "\n",
    "# 1) Building binary target from rating_text (0 = Poor/Average, 1 = Good/Very Good/Excellent)\n",
    "def map_label(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    t = str(s).strip().lower()\n",
    "    if t in [\"poor\", \"average\"]:\n",
    "        return 0\n",
    "    if t in [\"good\", \"very good\", \"excellent\"]:\n",
    "        return 1\n",
    "    return np.nan  \n",
    "\n",
    "data[\"label\"] = data[\"rating_text\"].apply(map_label)\n",
    "\n",
    "# 2) Tiny cuisine_count feature (numeric)\n",
    "def split_cuisines(v):\n",
    "    if pd.isna(v): return []\n",
    "    s = str(v).replace(\"/\", \",\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    return [p.strip().strip(\"'\").strip('\"') for p in s.split(\",\") if p.strip()]\n",
    "\n",
    "data[\"cuisine_count\"] = data.get(\"cuisine\", pd.Series([None]*len(data))).apply(lambda x: len(split_cuisines(x)))\n",
    "\n",
    "# 3) Clean numeric features\n",
    "data[\"cost\"]  = pd.to_numeric(data.get(\"cost\", 0), errors=\"coerce\")\n",
    "data[\"votes\"] = pd.to_numeric(data.get(\"votes\", 0), errors=\"coerce\")\n",
    "\n",
    "# 4) Selecting a small, stable feature set (avoid high-cardinality)\n",
    "feat_cols = [\"cost\", \"votes\", \"cuisine_count\", \"type\"]\n",
    "X = data[feat_cols].copy()\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Impute basics like: numerics->median, type->mode\n",
    "num_cols = [\"cost\", \"votes\", \"cuisine_count\"]\n",
    "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
    "if \"type\" in X.columns:\n",
    "    if X[\"type\"].isna().any():\n",
    "        X[\"type\"] = X[\"type\"].fillna(X[\"type\"].mode().iloc[0])\n",
    "\n",
    "# One-hot encode 'type' only (keeps dummies manageable)\n",
    "if \"type\" in X.columns:\n",
    "    X = pd.get_dummies(X, columns=[\"type\"], drop_first=True)\n",
    "\n",
    "# Drop rows with NaN labels\n",
    "mask = y.notna()\n",
    "X, y = X.loc[mask].reset_index(drop=True), y.loc[mask].astype(int).reset_index(drop=True)\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, y.values, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize only for models that need it (SVM/MLP); keep copies\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)\n",
    "\n",
    "# Baseline: Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "\n",
    "# Random Forest \n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "#  Gradient Boosting \n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "#  Linear SVM (needs standardized features) \n",
    "svm = LinearSVC(random_state=42)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred_svm = svm.predict(X_test_std)\n",
    "\n",
    "# Small MLP (needs standardized features) \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), activation=\"relu\", max_iter=500, random_state=42)\n",
    "mlp.fit(X_train_std, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test_std)\n",
    "\n",
    "#  Evaluation helpers \n",
    "def eval_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return cm, prec, rec, f1\n",
    "\n",
    "results = {}\n",
    "for name, pred in [\n",
    "    (\"LogReg\", y_pred_lr),\n",
    "    (\"RandForest\", y_pred_rf),\n",
    "    (\"GradBoost\", y_pred_gb),\n",
    "    (\"LinearSVM\", y_pred_svm),\n",
    "    (\"MLP\", y_pred_mlp),\n",
    "]:\n",
    "    cm, p, r, f = eval_metrics(y_test, pred)\n",
    "    results[name] = {\"precision\": p, \"recall\": r, \"f1\": f, \"confusion_matrix\": cm}\n",
    "\n",
    "# Print confusion matrices \n",
    "for name in results:\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Confusion matrix (rows = true, cols = pred):\\n\", results[name][\"confusion_matrix\"])\n",
    "    print(f\"Precision: {results[name]['precision']:.3f} | Recall: {results[name]['recall']:.3f} | F1: {results[name]['f1']:.3f}\")\n",
    "\n",
    "# Compact comparison table\n",
    "summary = pd.DataFrame({\n",
    "    k: {\"Precision\": v[\"precision\"], \"Recall\": v[\"recall\"], \"F1\": v[\"f1\"]}\n",
    "    for k, v in results.items()\n",
    "}).T.sort_values(\"F1\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Model comparison (sorted by F1) ===\")\n",
    "display(summary.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187fd64-4bbe-451d-baf6-928bfcf25599",
   "metadata": {},
   "source": [
    "Results (test set).\n",
    "\n",
    "1. Gradient Boosting had the best balance with F1 ≈ 0.814 (good precision and recall).\n",
    "\n",
    "2. MLP was next (F1 ≈ 0.800), then Random Forest (F1 ≈ 0.768).\n",
    "\n",
    "3. Logistic Regression and Linear SVM were weaker on recall, indicating more false negatives.\n",
    "\n",
    "Interpretation. Gradient Boosting captured non-linear patterns better than linear models. If we care more about recall (catching as many “good+” restaurants as possible), GB/MLP are preferable; if we value precision (fewer false positives), compare precision values in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33262b60-2532-477c-86c0-6d5ac5c315c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Part B\n",
    "# 4 Pyspark Models\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "CSV = r\"C:\\Users\\tobga\\OneDrive\\Desktop\\Data Science\\Sem 3\\Data sci technology and system\\Assignment 1\\zomato_df_final_data.csv\"\n",
    "\n",
    "sdf = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(CSV)\n",
    "for c in sdf.columns:\n",
    "    sdf = sdf.withColumnRenamed(c, c.strip().lower().replace(\" \", \"_\"))\n",
    "\n",
    "sdf = (sdf.withColumn(\"cost\", F.col(\"cost\").cast(\"double\"))\n",
    "         .withColumn(\"votes\", F.col(\"votes\").cast(\"double\"))\n",
    "         .withColumn(\"rating_number\", F.col(\"rating_number\").cast(\"double\")))\n",
    "\n",
    "clean = F.regexp_replace(F.regexp_replace(F.col(\"cuisine\"), r\"^\\[|\\]$\", \"\"), r\"[\\\"']\", \"\")\n",
    "parts = F.split(F.regexp_replace(clean, r\"/\", \",\"), r\"\\s*,\\s*\")\n",
    "sdf = sdf.withColumn(\"cuisine_count\", F.size(F.array_remove(parts, \"\")))\n",
    "sdf = sdf.withColumn(\"type\", F.when(F.col(\"type\").isNull(), \"Unknown\").otherwise(F.col(\"type\")))\n",
    "\n",
    "# Regression\n",
    "reg_df = sdf.select(\"rating_number\",\"cost\",\"votes\",\"cuisine_count\",\"type\").na.drop(subset=[\"rating_number\"])\n",
    "pipe_r = Pipeline(stages=[\n",
    "    Imputer(inputCols=[\"cost\",\"votes\",\"cuisine_count\"], outputCols=[\"cost_i\",\"votes_i\",\"cuisine_count_i\"], strategy=\"median\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_idx\", handleInvalid=\"keep\"),\n",
    "    OneHotEncoder(inputCol=\"type_idx\", outputCol=\"type_ohe\"),\n",
    "    VectorAssembler(inputCols=[\"cost_i\",\"votes_i\",\"cuisine_count_i\",\"type_ohe\"], outputCol=\"features\"),\n",
    "    LinearRegression(featuresCol=\"features\", labelCol=\"rating_number\")\n",
    "])\n",
    "train_r, test_r = reg_df.randomSplit([0.8, 0.2], seed=42)\n",
    "mse = RegressionEvaluator(labelCol=\"rating_number\", predictionCol=\"prediction\", metricName=\"mse\") \\\n",
    "        .evaluate(pipe_r.fit(train_r).transform(test_r))\n",
    "print(f\"\\nPySpark Regression — Test MSE: {mse:.4f}\")\n",
    "\n",
    "# Classification\n",
    "txt = F.lower(F.trim(F.col(\"rating_text\")))\n",
    "label = F.when(txt.isin(\"poor\",\"average\"), 0.0).when(txt.isin(\"good\",\"very good\",\"excellent\"), 1.0)\n",
    "clf_df = sdf.withColumn(\"label\", label).select(\"label\",\"cost\",\"votes\",\"cuisine_count\",\"type\").na.drop(subset=[\"label\"])\n",
    "\n",
    "pipe_c = Pipeline(stages=[\n",
    "    Imputer(inputCols=[\"cost\",\"votes\",\"cuisine_count\"], outputCols=[\"cost_i\",\"votes_i\",\"cuisine_count_i\"], strategy=\"median\"),\n",
    "    StringIndexer(inputCol=\"type\", outputCol=\"type_idx\", handleInvalid=\"keep\"),\n",
    "    OneHotEncoder(inputCol=\"type_idx\", outputCol=\"type_ohe\"),\n",
    "    VectorAssembler(inputCols=[\"cost_i\",\"votes_i\",\"cuisine_count_i\",\"type_ohe\"], outputCol=\"features\"),\n",
    "    LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "])\n",
    "pred = pipe_c.fit(clf_df.randomSplit([0.8, 0.2], seed=42)[0]).transform(clf_df.randomSplit([0.8, 0.2], seed=42)[1]) \\\n",
    "             .select(\"label\",\"prediction\")\n",
    "\n",
    "tp = pred.filter((F.col(\"label\")==1.0) & (F.col(\"prediction\")==1.0)).count()\n",
    "fp = pred.filter((F.col(\"label\")==0.0) & (F.col(\"prediction\")==1.0)).count()\n",
    "tn = pred.filter((F.col(\"label\")==0.0) & (F.col(\"prediction\")==0.0)).count()\n",
    "fn = pred.filter((F.col(\"label\")==1.0) & (F.col(\"prediction\")==0.0)).count()\n",
    "prec = tp/(tp+fp) if (tp+fp)>0 else 0.0\n",
    "rec  = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "f1   = (2*prec*rec)/(prec+rec) if (prec+rec)>0 else 0.0\n",
    "\n",
    "print(\"\\nPySpark Classification — Confusion [[TN FP] ; [FN TP]]\")\n",
    "print(f\"[[{tn} {fp}] ; [{fn} {tp}]]\")\n",
    "print(f\"Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2938598-c4dd-4acb-af47-b21969b7c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
